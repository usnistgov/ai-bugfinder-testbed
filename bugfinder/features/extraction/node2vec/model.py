from os import makedirs, listdir
from os.path import join, exists, splitext

import networkx as nx
import pandas as pd

from bugfinder.base.processing import AbstractProcessing
from bugfinder.features.extraction.node2vec import Node2VecImplementation
from bugfinder.settings import LOGGER


class Node2VecModel(AbstractProcessing):
    """Class for process the dataset and train a word2vec model using the node2vec
    algorithm to generate the corpus used as input
    """

    tokens = {}
    vector_length = 128
    walk_length = 50
    num_walks = 10
    p = 1
    q = 1
    window_dim = 10
    min_count = 1
    workers = 4
    algorithm = 1  # 1 = skipgram
    seed = 32

    def execute(self, name, **kwargs):
        """Run the processing. This function receives the processed dataset, retrieves
        all edges related to data and control flow (REACHES and FLOWS_TO), generates
        the graphs, run the node2vec algorithm to generate the random walks in the
        graphs, creates the model and saves it.

        Args:
            name (str): This parameter will be the name of the model saved in disk.
        """
        self.vector_length = kwargs["vec_length"]

        LOGGER.info("Creating the graph representation for training...")

        # Reads the dataset and saves all edges related to data/control flow
        edges = self._get_all_edges()

        graph = self._create_graph_object(edges)

        LOGGER.debug("Number of nodes in the graph: %d nodes", len(graph.nodes()))
        LOGGER.debug("Number of edges in the graph: %d edges", len(graph.edges))

        LOGGER.info("Initializing node2vec model...")

        # Creates the node2vec object which will execute the algorithm
        node2vec = Node2VecImplementation(
            graph,
            dimensions=self.vector_length,
            walk_length=self.walk_length,
            num_walks=self.num_walks,
            p=self.p,
            q=self.q,
            seed=self.seed,
        )

        # Train the model
        model = node2vec.fit(
            window=self.window_dim,
            min_count=self.min_count,
            vector_size=self.vector_length,
            workers=self.workers,
            sg=self.algorithm,
            seed=self.seed,
        )

        LOGGER.info("Training complete.")

        model_dir = join(self.dataset.model_dir, name)

        if not exists(self.dataset.model_dir):
            makedirs(self.dataset.model_dir)

        LOGGER.info("Saving the model at %s...", model_dir)

        model.save(model_dir)

    def _get_all_edges(self):
        """This function checks for edges CSV files generated by Joern, retrieves the
        nodes and edges related to data and control flows (REACHES and FLOWS_TO) as a
        dataframe, and appends each dataframe in a single one.

        Returns:
            edges_dataframe(pd.DataFrame): pandas dataframe containing all the edges
            necessary to create the graph object
        """
        edges_list = list()

        file_processing_list = [
            join(test_case, filepath)
            for test_case in self.dataset.test_cases
            for filepath in listdir(join(self.dataset.path, test_case))
            if splitext(filepath)[1] in [".csv"]
        ]

        while len(file_processing_list) != 0:
            filepath = file_processing_list.pop(0)

            in_path = join(self.dataset.path, filepath)

            if "edges" in in_path:
                csv_edge_file = pd.read_csv(
                    in_path, sep="\t", usecols=["start", "end", "type"]
                )

                if not csv_edge_file.empty:
                    csv_edge_file = csv_edge_file.loc[
                        (csv_edge_file["type"] == "REACHES")
                        | (csv_edge_file["type"] == "FLOWS_TO")
                    ]
                    LOGGER.debug(
                        "Processing %s: %d edges found.",
                        filepath,
                        len(csv_edge_file.index),
                    )

                    edges_list.append(csv_edge_file)
                else:
                    LOGGER.debug("Ignoring %s: Empty dataframe.", filepath)

        LOGGER.info(
            "List of edges succesfully created. %d files read. Creating dataframe...",
            len(edges_list),
        )

        edges_dataframe = pd.concat(edges_list, axis=0, ignore_index=True)

        del edges_list

        return edges_dataframe

    def _create_graph_object(self, edges):
        """Creates the graph object used by the node2vec algorithm.

        Args:
            edges_dataframe(pd.DataFrame): pandas dataframe containing all the edges
            necessary to create the graph object

        Returns:
            graph(nx.Graph): networkx graph type
        """
        graph = nx.Graph()
        graph = nx.from_pandas_edgelist(edges, "start", "end")

        return graph
