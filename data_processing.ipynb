{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing\n",
    "\n",
    "Notebook to interface with the raw CWE121 Juliet data. Make sure the data has been downloaded using `./tools/download_cwe121.sh`.\n",
    "\n",
    "## 1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "from os.path import realpath\n",
    "import logging\n",
    "from tools.settings import LOGGER\n",
    "\n",
    "LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset classes and processing operations\n",
    "from tools.dataset import CWEClassificationDataset as Dataset\n",
    "from tools.dataset.processing.dataset_ops import *\n",
    "from tools.dataset.processing.file_ops import *\n",
    "from tools.dataset.processing.content_ops import *\n",
    "\n",
    "# Dataset directories\n",
    "extracted_dataset_path = \"./data/cwe121_annot\"\n",
    "cleaned_dataset_path = \"./data/cwe121_dataset\"\n",
    "cwe121_1000_ref_dataset_path = \"./data/cwe121_1000\"\n",
    "cwe121_1000_dataset_path = \"./data/cwe121_1000a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the annotated dataset to avoid overwriting\n",
    "extracted_dataset = Dataset(extracted_dataset_path)\n",
    "extracted_dataset.queue_operation(CopyDataset, {\"to_path\": cleaned_dataset_path, \"force\": True})\n",
    "extracted_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup new dataset\n",
    "cleaned_dataset = Dataset(cleaned_dataset_path)\n",
    "\n",
    "cleaned_dataset.queue_operation(RemoveCppFiles)\n",
    "cleaned_dataset.queue_operation(RemoveMainFunction)\n",
    "cleaned_dataset.queue_operation(ReplaceLitterals)\n",
    "\n",
    "cleaned_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a subset of 1000 samples for training, test and validation purposes. \n",
    "cleaned_dataset.queue_operation(\n",
    "    ExtractSampleDataset, {\"to_path\": cwe121_1000_ref_dataset_path, \"sample_nb\": 1000, \"force\": True}\n",
    ")\n",
    "cleaned_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset for future references.\n",
    "cwe121_1000_ref_dataset = Dataset(cwe121_1000_ref_dataset_path)\n",
    "cwe121_1000_ref_dataset.queue_operation(CopyDataset, {\"to_path\": cwe121_1000_dataset_path, \"force\": True})\n",
    "\n",
    "cwe121_1000_ref_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset that is going to be used\n",
    "cwe121_1000_dataset = Dataset(cwe121_1000_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply joern\n",
    "\n",
    "In this step, the code will be transform in a graph and stored in a Neo4J database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.libs.joern.v040 import main as run_joern_v040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_joern_v040(realpath(cwe121_1000_dataset.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Markup AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.libs.ast.v02 import main as ast_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_v02(realpath(\"%s/neo4j_v3.db\" % cwe121_1000_dataset.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.features.rel_count_single_hop_v02 import extract_features\n",
    "from tools.libs.neo4j.ai import start_container as run_neo4j_v3\n",
    "from tools.utils.containers import stop_container_by_name\n",
    "from py2neo import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = realpath(\"%s/neo4j_v3.db\" % cwe121_1000_dataset.path)\n",
    "\n",
    "neo4j_container_obj, neo4j_container_name = run_neo4j_v3(db_path, stop_after_execution=False)\n",
    "\n",
    "# Neo4j database pre-loaded with Joern\n",
    "neo4j_db = Graph(\n",
    "    scheme=\"http\",\n",
    "    host=\"0.0.0.0\",\n",
    "    port=\"7474\"\n",
    ")\n",
    "\n",
    "extract_features(neo4j_db, cwe121_1000_dataset.path)\n",
    "\n",
    "stop_container_by_name(neo4j_container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format feature files\n",
    "\n",
    "This step will convert feature files to csv for easy import in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = \"%s/features/features.mtx\" % cwe121_1000_dataset.path\n",
    "labels_filename = \"%s/features/labels.txt\" % cwe121_1000_dataset.path\n",
    "\n",
    "features_csv_filename = \"%s/features/features.csv\" % cwe121_1000_dataset.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(labels_filename, delimiter=',', dtype=None)\n",
    "labels = pd.DataFrame(labels)\n",
    "labels[\"results\"] = labels[\"f0\"].apply(lambda it: 1 if it else 0)\n",
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mmread(features_filename).tocsr()\n",
    "features = pd.DataFrame(features.todense())\n",
    "features.columns = [str(c) for c in features.columns]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_cols = list()\n",
    "\n",
    "for col in features:\n",
    "    for item in features[col]:\n",
    "        if item != 0:\n",
    "            non_empty_cols.append(col)\n",
    "            break\n",
    "\n",
    "empty_cols = [col for col in features if col not in non_empty_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = features.drop(empty_cols, axis=1)\n",
    "simple_features[\"results\"] = labels[\"results\"]\n",
    "\n",
    "simple_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features.to_csv(features_csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the feature and dump them in a CSV file\n",
    "feature_filename = \"%s/features/features.csv\" % cwe121_1000_dataset.path\n",
    "feats = pd.read_csv(feature_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = feats[\"results\"]\n",
    "output_data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = feats.drop(\"results\", axis=1)\n",
    "input_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_data, output_data, test_size=0.33, random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = list()\n",
    "feat_cols_append = feat_cols.append\n",
    "\n",
    "for x in X_train.columns:\n",
    "    feat_cols_append(tf.feature_column.numeric_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, shuffle=True, batch_size=100, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_cls_model = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_cls_model.train(input_fn=input_fn, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=X_test,\n",
    "    y=y_test,\n",
    "    batch_size=10,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lin_cls_model.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
