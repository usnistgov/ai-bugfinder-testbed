{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Joern Processing\n",
    "\n",
    "In this notebook, the [previously created](./01_pre_processing.ipynb) dataset will be parsed using various version of Joern. The parsed data will then be imported or converted into a Neo4J v3 database for further processing.\n",
    "\n",
    "## 02.a.  Imports, logging configuration and dataset preparation\n",
    "\n",
    "The first step is to perform the necessary imports and configure the program. Additionnally, the previously used dataset is copied into 3 different datasets to be processed by the various Joern versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable these line if live changes in the codebase are made\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific instruction to run the notebooks from a sub-folder.\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from bugfinder.settings import LOGGER\n",
    "from bugfinder.dataset import CWEClassificationDataset as Dataset\n",
    "from bugfinder.dataset.processing.dataset_ops import CopyDataset, RightFixer\n",
    "from bugfinder.joern.v031 import JoernDatasetProcessing as Joern031DatasetProcessing\n",
    "from bugfinder.joern.v040 import JoernDatasetProcessing as Joern040DatasetProcessing\n",
    "from bugfinder.neo4j.converter import Neo4J2Converter, Neo4J3Converter\n",
    "from bugfinder.neo4j.importer import Neo4J3Importer\n",
    "from bugfinder.neo4j.annot import Neo4JAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to only output INFO level messages\n",
    "LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directories (DO NOT EDIT)\n",
    "dataset_path = \"../data/ai-dataset_v000\"\n",
    "v100_dataset_path = \"../data/ai-dataset_v100\"\n",
    "v200_dataset_path = \"../data/ai-dataset_v200\"\n",
    "# v300_dataset_path = \"../data/ai-dataset_v300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset into 3 different dataset for future use.\n",
    "dataset = Dataset(dataset_path)\n",
    "dataset.queue_operation(CopyDataset, {\"to_path\": v100_dataset_path, \"force\": True})\n",
    "dataset.queue_operation(CopyDataset, {\"to_path\": v200_dataset_path, \"force\": True})\n",
    "# dataset.queue_operation(CopyDataset, {\"to_path\": v300_dataset_path, \"force\": True})\n",
    "\n",
    "dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.b. Joern v0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset that is going to be used\n",
    "v100_dataset = Dataset(v100_dataset_path)\n",
    "\n",
    "# Apply Joern 3.1 conversion and import into Neo4J v3\n",
    "v100_dataset.queue_operation(Joern031DatasetProcessing)\n",
    "v100_dataset.queue_operation(Neo4J2Converter)\n",
    "v100_dataset.queue_operation(Neo4J3Converter)\n",
    "v100_dataset.queue_operation(Neo4JAnnotations)\n",
    "\n",
    "v100_dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.c. Joern v0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset that is going to be used\n",
    "v200_dataset = Dataset(v200_dataset_path)\n",
    "\n",
    "# Apply Joern 4.0 conversion and import into Neo4J v3\n",
    "v200_dataset.queue_operation(Joern040DatasetProcessing)\n",
    "v200_dataset.queue_operation(Neo4J3Importer)\n",
    "v200_dataset.queue_operation(Neo4JAnnotations)\n",
    "\n",
    "v200_dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.d. Joern v1.0\n",
    "\n",
    "*Currently in development. Coming soonâ„¢...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserved space for future Joern version\n",
    "# v300_dataset = Dataset(v300_dataset_path)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, the cleaned dataset was parsed using various Joern version and is now ready to be further processed in Neo4J. The [next notebook](./03_neo4j_processing.ipynb) details the step continue the processing before the feature extraction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
