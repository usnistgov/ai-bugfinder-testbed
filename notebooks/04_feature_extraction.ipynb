{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Feature extraction \n",
    "\n",
    "In this notebook, features will be extracted from the [previously annotated](./03_neo4j_processing.ipynb). This step allows to train the neural network in the final step.\n",
    "\n",
    "Please note that the current extractors retrieve counts of links between two nodes such as: **source**-**flow**-**sink**. \n",
    "\n",
    "Source and sink nodes are formated according to the AST markup that has been computed in step in the [previous notebook](./03_neo4j_processing.ipynb). For each extractors, a features list are created with `dataset.queue_operation(ExtractorClass, {\"need_map_features\": True})`. This feature list has to be computed only once and serves to determine the list of labels needed for the feature extractor.\n",
    "\n",
    "## 04.a. Imports, logging configuration and dataset preparation\n",
    "\n",
    "The first step is to perform the necessary imports and configure the program. Additionnally, the previously used datasets are copied into 3 different datasets to have their features extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable these line if live changes in the codebase are made\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific instruction to run the notebooks from a sub-folder.\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from bugfinder.settings import LOGGER\n",
    "from bugfinder.dataset import CWEClassificationDataset as Dataset\n",
    "from bugfinder.dataset.processing.dataset_ops import CopyDataset, RightFixer\n",
    "from bugfinder.features.extraction.any_hop.all_flows import FeatureExtractor as AnyHopAllFlowsExtractor\n",
    "from bugfinder.features.extraction.any_hop.single_flow import FeatureExtractor as AnyHopSingleFlowExtractor\n",
    "from bugfinder.features.extraction.single_hop.raw import FeatureExtractor as SingleHopRawExtractor\n",
    "from bugfinder.features.extraction.hops_n_flows import FeatureExtractor as HopsNFlowsExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to only output INFO level messages\n",
    "LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directories (DO NOT EDIT)\n",
    "cwe121_v__0_dataset_path = [\n",
    "    \"../data/cwe121_v110\", \"../data/cwe121_v120\", \"../data/cwe121_v210\", \"../data/cwe121_v220\", \n",
    "#     \"../data/cwe121_v310\", \"../data/cwe121_v320\"\n",
    "]\n",
    "# cwe121_v__1_dataset_path = [\n",
    "#     \"../data/cwe121_v111\", \"../data/cwe121_v121\", \"../data/cwe121_v211\", \"../data/cwe121_v221\", \n",
    "# #     \"../data/cwe121_v311\", \"../data/cwe121_v321\"\n",
    "# ]\n",
    "cwe121_v__2_dataset_path = [\n",
    "    \"../data/cwe121_v112\", \"../data/cwe121_v122\", \"../data/cwe121_v212\", \"../data/cwe121_v222\", \n",
    "#     \"../data/cwe121_v312\", \"../data/cwe121_v322\"\n",
    "]\n",
    "cwe121_v__3_dataset_path = [\n",
    "    \"../data/cwe121_v113\", \"../data/cwe121_v123\", \"../data/cwe121_v213\", \"../data/cwe121_v223\", \n",
    "#     \"../data/cwe121_v313\", \"../data/cwe121_v323\"\n",
    "]\n",
    "# cwe121_v__4_dataset_path = [\n",
    "#     \"../data/cwe121_v114\", \"../data/cwe121_v124\", \"../data/cwe121_v214\", \"../data/cwe121_v224\", \n",
    "#     \"../data/cwe121_v314\", \"../data/cwe121_v324\"\n",
    "# ]\n",
    "\n",
    "dataset_to_copy = [\n",
    "#     cwe121_v__1_dataset_path, cwe121_v__2_dataset_path, cwe121_v__3_dataset_path, cwe121_v__4_dataset_path\n",
    "    cwe121_v__2_dataset_path, cwe121_v__3_dataset_path\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary dataset clones\n",
    "from os.path import basename\n",
    "\n",
    "LOGGER.info(\"Starting datasets copy...\")\n",
    "LOGGER.setLevel(logging.WARNING)\n",
    "\n",
    "for index in range(len(cwe121_v__0_dataset_path)):\n",
    "    cwe121_dataset = Dataset(cwe121_v__0_dataset_path[index])\n",
    "    \n",
    "    for dataset_paths in dataset_to_copy:\n",
    "        cwe121_dataset.queue_operation(CopyDataset, {\"to_path\": dataset_paths[index], \"force\": True})\n",
    "        \n",
    "    cwe121_dataset.process()\n",
    "    print(\"Dataset %s copied.\" % basename(cwe121_v__0_dataset_path[index]))\n",
    "    \n",
    "LOGGER.setLevel(logging.INFO)\n",
    "LOGGER.info(\"Datasets copied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.b. AnyHop AllFlow (DEPRECATED)\n",
    "\n",
    "This extractor retrieves any node labelled `UpstreamNode` (named **root1**) up to 5 hops away from the function entrypoint. Then, any node labelled `DownstreamNode` (named **root2**), located up to 3 hops away from **root1** is extracted. Node **root1** is designated as the source, **root2** is the sink and the flow is a chain of the relationships between nodes. This chain has the following format: **R1:R2:...:Rn**, where **Ri** could be `FLOWS_TO`, `REACHES` or `CONTROLS` relationship. Each extracted feature is then added to the feature map as single item.\n",
    "\n",
    "**Warning:** The AnyHopAllFlowsExtractor is being deprecated and will be removed in a future version. This part of the notebook will be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_path in cwe121_v__1_dataset_path:\n",
    "#     LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "#     dataset = Dataset(dataset_path)\n",
    "#     dataset.queue_operation(AnyHopAllFlowsExtractor, {\"need_map_features\": True})\n",
    "#     dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_path in cwe121_v__1_dataset_path:\n",
    "#     LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "#     dataset = Dataset(dataset_path)\n",
    "#     dataset.queue_operation(AnyHopAllFlowsExtractor)\n",
    "#     dataset.queue_operation(PCA, {\"final_dimension\": 50})\n",
    "#     dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.c. SingleHop\n",
    "\n",
    "This extractor retrieves any node labelled `UpstreamNode` (named **root1**) 1 hop away from any node labelled `DownstreamNode` (named **root2**), and part of the function graph. Node **root1** is designated as the source, **root2** is the sink and the flow is the relationship between nodes. This chain has the following format: **Ri** which could be `FLOWS_TO`, `REACHES` or `CONTROLS` relationship. Each extracted feature is then counted and added to the feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__2_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(SingleHopRawExtractor, {\"need_map_features\": True})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__2_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(SingleHopRawExtractor)\n",
    "#     dataset.queue_operation(PCA, {\"final_dimension\": 50})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.d. AnyHop SingleFlow\n",
    "\n",
    "This extractor retrieves any node labelled `UpstreamNode` (named **root1**) n hop away from any node labelled `DownstreamNode` (named **root2**), and part of the function graph. Node **root1** is designated as the source, **root2** is the sink and the flow is the relationship between nodes. This chain has the following format: **Ri** which could be `FLOWS_TO`, `REACHES` or `CONTROLS` relationship. Each extracted feature is then counted and added to the feature map. This extractor normalizes the columns (`feat_col = feat_count / test_case_count`) for every entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__3_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(AnyHopSingleFlowExtractor, {\"need_map_features\": True})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__3_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(AnyHopSingleFlowExtractor)\n",
    "#     dataset.queue_operation(PCA, {\"final_dimension\": 50})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.e. Hops and flows\n",
    "\n",
    "This extractor retrieves any node labelled `UpstreamNode` (named **root1**) `n` hops away from any node labelled `DownstreamNode` (named **root2**), and part of the function graph. The number of hops `n` is an integer within the range [`min_hops`, `max_hops`], where `min_hops > 0` and `max_hops > min_hops`. If `max_hops` is -1, the extractor retrieves all possible relationship.\n",
    "\n",
    "Node **root1** is designated as the source, **root2** is the sink and the flow is the relationship between nodes. This chain has the following format: **Ri** which could be `FLOWS_TO`, `REACHES` or `CONTROLS` relationship. Each extracted feature is then counted and added to the feature map. This extractor normalizes the columns (`feat_col = feat_count / test_case_count`) for every entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__3_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(HopsNFlowsExtractor, {\"min_hops\": 1, \"max_hops\": -1, \"need_map_features\": True})\n",
    "    dataset.queue_operation(HopsNFlowsExtractor, {\"max_hops\": -1})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__3_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(HopsNFlowsExtractor, {\"min_hops\": 1, \"max_hops\": -1})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, the previously annotated datasets had several feature extracted. The [next notebook](./05_dimension_reduction.ipynb) trains the models and retrieve the results obtained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
