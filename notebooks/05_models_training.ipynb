{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Models training\n",
    "\n",
    "In the previous notebooks, the dataset were curated and several feature extracted to train various machine learning models. In this notebook, the model will be initialized and trained with the various dataset. The dataset is split 80/20, respectively, for training and testing.\n",
    "\n",
    "## 05.a. Imports, logging configuration and dataset preparation\n",
    "\n",
    "The first step is to perform the necessary imports and configure the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable these line if live changes in the codebase are made\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow logging\n",
    "import os\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific instruction to run the notebooks from a sub-folder.\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from bugfinder.settings import LOGGER\n",
    "from bugfinder.dataset import CWEClassificationDataset as Dataset\n",
    "from bugfinder.models.dnn_classifier import DNNClassifierTraining\n",
    "from bugfinder.models.linear_classifier import LinearClassifierTraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to only output INFO level messages\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "LOGGER.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directories (DO NOT EDIT)\n",
    "cwe121_v__0_dataset_path = [\n",
    "    \"../data/cwe121_v110\", \"../data/cwe121_v120\", \"../data/cwe121_v210\", \"../data/cwe121_v220\", \n",
    "#     \"../data/cwe121_v310\", \"../data/cwe121_v320\"\n",
    "]\n",
    "cwe121_v__1_dataset_path = [\n",
    "    \"../data/cwe121_v111\", \"../data/cwe121_v121\", \"../data/cwe121_v211\", \"../data/cwe121_v221\", \n",
    "#     \"../data/cwe121_v311\", \"../data/cwe121_v321\"\n",
    "]\n",
    "cwe121_v__2_dataset_path = [\n",
    "    \"../data/cwe121_v112\", \"../data/cwe121_v122\", \"../data/cwe121_v212\", \"../data/cwe121_v222\", \n",
    "#     \"../data/cwe121_v312\", \"../data/cwe121_v322\"\n",
    "]\n",
    "cwe121_v__3_dataset_path = [\n",
    "    \"../data/cwe121_v113\", \"../data/cwe121_v123\", \"../data/cwe121_v213\", \"../data/cwe121_v223\", \n",
    "#     \"../data/cwe121_v313\", \"../data/cwe121_v323\"\n",
    "]\n",
    "# cwe121_v__4_dataset_path = [\n",
    "#     \"../data/cwe121_v114\", \"../data/cwe121_v124\", \"../data/cwe121_v214\", \"../data/cwe121_v224\", \n",
    "#     \"../data/cwe121_v314\", \"../data/cwe121_v324\"\n",
    "# ]\n",
    "\n",
    "dataset_to_copy = [\n",
    "#     cwe121_v__1_dataset_path, cwe121_v__2_dataset_path, cwe121_v__3_dataset_path, cwe121_v__4_dataset_path\n",
    "    cwe121_v__1_dataset_path, cwe121_v__2_dataset_path, cwe121_v__3_dataset_path\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.b. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__1_dataset_path:\n",
    "    LOGGER.info(\"Processing %s (Epoch %d)...\" % (dataset_path, e))\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(LinearClassifierTraining, {\"name\": \"lin-cls\", \"reset\": True})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.c. Multilayer Perceptron (default size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__1_dataset_path:\n",
    "    LOGGER.info(\"Processing %s...\" % dataset_path)\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(DNNClassifierTraining, {\"name\": \"dnn-default\", \"reset\": True})\n",
    "    dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.d. Multilayer Perceptron (configured size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_path in cwe121_v__1_dataset_path:\n",
    "    LOGGER.info(\"Processing %s (Epoch %d)...\" % (dataset_path, e))\n",
    "    dataset = Dataset(dataset_path)\n",
    "    dataset.queue_operation(DNNClassifierTraining, {\"name\": \"dnn-custom\", \"architecture\": [25, 50, 75, 50, 25], \n",
    "                                                    \"reset\": True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
