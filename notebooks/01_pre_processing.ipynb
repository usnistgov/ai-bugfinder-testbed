{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Pre-processing\n",
    "\n",
    "This notebook will pre-process a classified C/C++ dataset extracted from [Juliet 1.3](https://samate.nist.gov/SRD/testsuite.php) to ensure correct formatting before the Joern parsing.\n",
    "\n",
    "Download the dataset using the script at `../scripts/download_cwe121.sh`. In the **data** directory, the following directories should be present:\n",
    "* **cwe121_annot**: classified dataset with bad (buggy) and good (fixed) classes.\n",
    "* **cwe121_orig**: original dataset, unzipped version of the next file.\n",
    "* **Juliet_Test_Suite_v1.3_for_C_Cpp.zip**: dataset downloaded from the SARD website.\n",
    "\n",
    "## 01.a. Imports and logging configuration\n",
    "\n",
    "The first step is to perform the necessary imports and configure the program. Additionally, if the dataset need to be downloaded, it can be done in the last cell of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific instruction to run the notebooks from a sub-folder.\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tools.settings import LOGGER\n",
    "from tools.dataset import CWEClassificationDataset as Dataset\n",
    "from tools.dataset.processing.content_ops import RemoveMainFunction, ReplaceLitterals\n",
    "from tools.dataset.processing.dataset_ops import CopyDataset, ExtractSampleDataset\n",
    "from tools.dataset.processing.file_ops import RemoveCppFiles, RemoveInterproceduralTestCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to only output INFO level messages\n",
    "LOGGER.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directories (DO NOT EDIT)\n",
    "classified_dataset_path = \"../data/cwe121_annot\"\n",
    "cleaned_dataset_path = \"../data/cwe121_dataset\"\n",
    "cwe121_dataset_path = \"../data/cwe121_v000_orig\"\n",
    "\n",
    "# Number of sample to test (edit this number, performances will be impacted, max. 6288)\n",
    "sample_nb = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Step: Download the dataset\n",
    "\n",
    "Use the following cell to download the dataset. Beware that <u>it will use all available CPUs</u> and can take a long time. The cell needs to be run only if the dataset is not present or has been tampered with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-03 09:37:27][INFO] CWE-121 dataset has been downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download the CWE-121 from Juliet 1.3 and classify the samples between good and bad classes.\n",
    "import subprocess\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "\n",
    "force_download = False  # Change to True if the dataset has been tampered with\n",
    "download_dir = \"../data/cwe121_annot/bad\"\n",
    "need_download = (not isdir(download_dir) or len(listdir(download_dir)) != 4944)\n",
    "\n",
    "if need_download or force_download:\n",
    "    LOGGER.info(\"Downloading CWE-121 dataset...\")\n",
    "    subprocess.run(\"../scripts/download_cwe121.sh\")\n",
    "\n",
    "LOGGER.info(\"CWE-121 dataset has been downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.b. Cleanup\n",
    "\n",
    "Cleanup the downloaded data to ensure correct parsing in the future steps. The dataset will be stored in **./data/cwe121_dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-03 16:35:48][INFO] Dataset index build in 376ms. 9888 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:48][INFO] Running operation 1/1 (CopyDataset)...\n",
      "[2019-12-03 16:35:48][INFO] Dataset index build in 199ms. 6288 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:48][INFO] Running operation 1/1 (RightFixer)...\n",
      "[2019-12-03 16:35:49][INFO] 1 operations run in 1099ms.\n",
      "[2019-12-03 16:35:52][INFO] 1 operations run in 4382ms.\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the annotated dataset to avoid overwriting\n",
    "classified_dataset = Dataset(classified_dataset_path)\n",
    "classified_dataset.queue_operation(CopyDataset, {\"to_path\": cleaned_dataset_path, \"force\": True})\n",
    "classified_dataset.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-03 16:35:53][INFO] Dataset index build in 424ms. 9888 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:53][INFO] Running operation 1/4 (RemoveCppFiles)...\n",
      "[2019-12-03 16:35:53][INFO] Dataset index build in 287ms. 8684 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:53][INFO] Running operation 2/4 (RemoveInterproceduralTestCases)...\n",
      "[2019-12-03 16:35:54][INFO] Dataset index build in 226ms. 6288 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:54][INFO] Running operation 3/4 (RemoveMainFunction)...\n",
      "[2019-12-03 16:35:57][INFO] Dataset index build in 184ms. 6288 test_cases, 2 classes, 0 features (v0).\n",
      "[2019-12-03 16:35:57][INFO] Running operation 4/4 (ReplaceLitterals)...\n",
      "[2019-12-03 16:36:03][INFO] 4 operations run in 10603ms.\n"
     ]
    }
   ],
   "source": [
    "# Cleanup new dataset\n",
    "cleaned_dataset = Dataset(cleaned_dataset_path)\n",
    "\n",
    "cleaned_dataset.queue_operation(RemoveCppFiles)\n",
    "cleaned_dataset.queue_operation(RemoveInterproceduralTestCases)\n",
    "cleaned_dataset.queue_operation(RemoveMainFunction)\n",
    "cleaned_dataset.queue_operation(ReplaceLitterals)\n",
    "\n",
    "cleaned_dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.c. Subset extraction\n",
    "\n",
    "Extract a subset of the data for testing purposes at **./data/cwe121_training_orig**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-03 16:36:03][INFO] Running operation 1/1 (ExtractSampleDataset)...\n",
      "[2019-12-03 16:36:03][INFO] 1 operations run in 125ms.\n",
      "[2019-12-03 16:36:04][INFO] Dataset index build in 7ms. 200 test_cases, 2 classes, 0 features (v0).\n"
     ]
    }
   ],
   "source": [
    "# Extract a subset of 1000 samples for training, test and validation purposes. \n",
    "cleaned_dataset.queue_operation(\n",
    "    ExtractSampleDataset, {\"to_path\": cwe121_dataset_path, \"sample_nb\": sample_nb, \"force\": True}\n",
    ")\n",
    "cleaned_dataset.process()\n",
    "\n",
    "# Open the dataset to see its statistics.\n",
    "cwe121_dataset = Dataset(cwe121_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this part, the initial dataset was cleaned and is now ready to be processed by Joern. The [next notebook](./02_joern_processing.ipynb) details the step to run Joern and import the dataset into a Neo4J database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
